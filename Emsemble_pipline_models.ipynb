{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de Ensemble por Modelos (SA → MA)\n",
    "\n",
    "Este notebook detalha, passo a passo, o processo de ensemble em dois níveis:\n",
    "\n",
    "- Single-Architecture (SA): ensemble por modelo, nos níveis Tile → Image → Patient.\n",
    "- Multi-Architecture (MA): ensemble entre diferentes modelos, nos níveis Image → Tile → Patient.\n",
    "\n",
    "Ao final, os artefatos (CSVs e métricas) são organizados em \n",
    "`outputs/tables` (tabelas geradas) e `outputs/results` (artefatos para consulta/apresentação).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fca021",
   "metadata": {},
   "source": [
    "## 1. Configuração Geral\n",
    "Defina: modelos a incluir, tipo de ensemble e métrica de peso (quando weighted).\n",
    "Os dados de entrada dos folds por arquitetura estão em `datas/summary_results_<modelo>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42983589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.metrics import generate_ma_metrics_from_tables, generate_sa_metrics_from_tables\n",
    "from modules.utils import log, discover_models_and_paths\n",
    "from modules.utils import resolve_paths_outputs\n",
    "import modules.flags as flags\n",
    "import os, json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85512b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurar flags (plots opcionais para soft_voting)\n",
    "flags.GENERATE_LEVELS = ['tile', 'image', 'patient']\n",
    "if 'soft_voting' not in flags.GENERATE_PLOTS_FOR:\n",
    "    flags.GENERATE_PLOTS_FOR.append('soft_voting')\n",
    "\n",
    "MODELS = ['EFFNet', 'GGNet', 'MOBNet']\n",
    "ENSEMBLE_TYPE = 'soft_voting'  # 'hard_voting' | 'soft_voting' | 'weighted'\n",
    "WEIGHT_METRIC = 'f1_macro'     # usado apenas com 'weighted'\n",
    "TABLES_DIR, _ = resolve_paths_outputs()\n",
    "OUTPUT_FILENAME = \"tasks.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d3a8b",
   "metadata": {},
   "source": [
    "## 2. Descoberta dos CSVs de Folds (datas/)\n",
    "Mostra quantos CSVs foram encontrados por arquitetura e um exemplo de arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98f7bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Preparação de Tarefas ---\n",
      "[INFO] Buscando modelos especificados: ['EFFNet', 'GGNet', 'MOBNet']\n",
      "\n",
      "--- Relatório de Descoberta ---\n",
      "EFFNet: 10 CSVs encontrados\n",
      "------------------------------------------------------------\n",
      "GGNet: 10 CSVs encontrados\n",
      "------------------------------------------------------------\n",
      "MOBNet: 10 CSVs encontrados\n",
      "------------------------------------------------------------\n",
      "[INFO] Modelos configurados para execução: ['EFFNet', 'GGNet', 'MOBNet']\n",
      "\n",
      "[SUCESSO] Arquivo 'tasks.json' gerado com 3 tarefas.\n",
      "Agora você pode mover este arquivo e rodar o script 'execute_tasks.py'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"--- Iniciando Preparação de Tarefas ---\")\n",
    "\n",
    "try:\n",
    "    # 2. DESCUBRA OS MODELOS E SEUS CAMINHOS\n",
    "    models_and_paths = discover_models_and_paths(models_to_find=MODELS)\n",
    "\n",
    "    if not models_and_paths:\n",
    "        print(\"[INFO] Nenhum modelo válido foi encontrado. Nenhum arquivo de tarefas gerado.\")\n",
    "        exit()\n",
    "\n",
    "    # 3. PREPARE A LISTA DE CONFIGURAÇÕES (O CONTEÚDO DO FUTURO JSON)\n",
    "    configs_to_save = []\n",
    "    for model_name, csv_path_list in models_and_paths.items():\n",
    "        if not csv_path_list:\n",
    "            print(f\"[AVISO] Modelo '{model_name}' não possui CSVs e será ignorado.\")\n",
    "            continue\n",
    "\n",
    "        config = {\n",
    "            'model_name': model_name,\n",
    "            'ensemble_type': ENSEMBLE_TYPE,\n",
    "            'weight_metric': WEIGHT_METRIC,\n",
    "            'csv_paths': csv_path_list,\n",
    "        }\n",
    "        configs_to_save.append(config)\n",
    "    \n",
    "    # 4. SALVE AS CONFIGURAÇÕES EM UM ARQUIVO JSON\n",
    "    with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "        json.dump(configs_to_save, f, indent=4)\n",
    "\n",
    "    print(f\"\\n[SUCESSO] Arquivo '{OUTPUT_FILENAME}' gerado com {len(configs_to_save)} tarefas.\")\n",
    "    print(\"Agora você pode mover este arquivo e rodar o script 'execute_tasks.py'.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n[ERRO CRÍTICO] {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERRO INESPERADO] Ocorreu um erro durante a preparação: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bdaacc",
   "metadata": {},
   "source": [
    "## 3. Ensemble por Modelo (SA): Tile → Image → Patient\n",
    "Nesta etapa consolidamos os folds de um mesmo modelo em três níveis.\n",
    "Os resultados são salvos em `outputs/tables/<Modelo>/Ensemble_<level>_<tipo>/`.\n",
    "Depois, exportamos artefatos para `outputs/results/SA/<Modelo>/<tipo>/<Level>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632a579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:05] [SA] Iniciando execução com paralelização e cache interno (tile → image → patient)...\n",
      "[13:53:05] [SA] Iniciando execução do pipeline SA para 3 modelos (tile → image → patient)...\n",
      "[13:53:05] [INICIANDO] Processamento do modelo: EFFNet\n",
      "[13:53:05] [INICIANDO] Processamento do modelo: GGNet\n",
      "[13:53:05] [SA] EFFNet → tile\n",
      "[13:53:05] [INICIANDO] Processamento do modelo: MOBNet\n",
      "[13:53:05] [SA] GGNet → tile\n",
      "[13:53:05] [SA] MOBNet → tile\n",
      "[14:02:09] [SA] EFFNet → image\n",
      "[14:02:19] [SA] MOBNet → image\n",
      "[14:02:32] [SA] GGNet → image\n",
      "[14:04:19] [SA] EFFNet → patient\n",
      "[14:04:36] [SA] MOBNet → patient\n",
      "[14:04:52] [SA] GGNet → patient\n",
      "[14:06:28] [AVISO] Falha ao exportar SA para EFFNet: name 'export_sa_to_results' is not defined\n",
      "[14:06:28] [CONCLUÍDO] Processamento do modelo: EFFNet\n",
      "[14:06:41] [AVISO] Falha ao exportar SA para MOBNet: name 'export_sa_to_results' is not defined\n",
      "[14:06:41] [CONCLUÍDO] Processamento do modelo: MOBNet\n",
      "[14:06:50] [AVISO] Falha ao exportar SA para GGNet: name 'export_sa_to_results' is not defined\n",
      "[14:06:50] [CONCLUÍDO] Processamento do modelo: GGNet\n",
      "[14:06:50] \n",
      "--- Pipeline SA Finalizado ---\n",
      "[14:06:50] Resultados das execuções:\n",
      "[14:06:50]  - EFFNet: Concluído\n",
      "[14:06:50]  - GGNet: Concluído\n",
      "[14:06:50]  - MOBNet: Concluído\n"
     ]
    }
   ],
   "source": [
    "from modules.runner_sa import run_sa_for_models_parallel\n",
    "# Execução do pipeline SA\n",
    "\n",
    "INPUT_FILENAME = \"tasks.json\"\n",
    "if not os.path.exists(INPUT_FILENAME):\n",
    "    raise FileNotFoundError(f\"Arquivo de plano de execução '{INPUT_FILENAME}' não encontrado!\")\n",
    "\n",
    "with open(INPUT_FILENAME, 'r', encoding='utf-8') as f:\n",
    "    lista_de_configs = json.load(f)\n",
    "\n",
    "log(\"[SA] Iniciando execução com paralelização e cache interno (tile → image → patient)...\")\n",
    "# Sumário dos artefatos gerados\n",
    "# -----------------------------------------\n",
    "run_sa_for_models_parallel(TABLES_DIR, lista_de_configs, max_workers=4, use_threads=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73bca6",
   "metadata": {},
   "source": [
    "#### **[SA]  Gerar Métricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sa_metrics_from_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3923ce17",
   "metadata": {},
   "source": [
    "## 4. Ensemble Entre Modelos (MA)\n",
    "Combina as saídas SA dos modelos selecionados.\n",
    "Os resultados são salvos em `outputs/tables/Ensemble_Between_Models/...` \n",
    "e exportados para `outputs/results/MA/<tipo>/<Level>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3b202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:06:50] \n",
      "[MA] Rodando ensemble entre modelos para os tipos: soft_voting ...\n",
      "[14:06:50] [MA] Iniciando pipeline de Ensemble Entre Modelos para: ['EFFNet', 'GGNet', 'MOBNet']\n",
      "[14:06:50] [MA] Tipo de Ensemble a ser executado: 'soft_voting'\n",
      "[14:06:50] [MA] Resultados serão salvos em: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\n",
      "[14:06:50] [MA INICIANDO] Executando ensemble 'soft_voting' para o nível 'tile'...\n",
      "[14:06:50] [MA INICIANDO] Executando ensemble 'soft_voting' para o nível 'image'...\n",
      "[14:06:50] [MA INICIANDO] Executando ensemble 'soft_voting' para o nível 'patient'...\n",
      "[14:06:50] [MA SUCESSO] Nível 'image' (soft_voting) concluído. CSV salvo em: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\ImageLevel_Ensemble_Models_soft_voting\\ensemble_between_models_per_image_soft_voting.csv\n",
      "[14:06:50] [MA SUCESSO] Nível 'patient' (soft_voting) concluído. CSV salvo em: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\PatientLevel_Ensemble_soft_voting\\ensemble_between_models_per_patient_soft_voting.csv\n",
      "[14:07:45] [MA SUCESSO] Nível 'tile' (soft_voting) concluído. CSV salvo em: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\TileLevel_Ensemble_Models_soft_voting\\ensemble_between_models_tile_level_soft_voting.csv\n",
      "[14:07:45] \n",
      "--- Pipeline MA (Ensemble Entre Modelos) Finalizado ---\n",
      "[14:07:45] Resultados das execuções:\n",
      "[14:07:45]  - Nível: tile     | Status: Sucesso | Detalhe: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\TileLevel_Ensemble_Models_soft_voting\\metrics_tile_level_soft_voting.json\n",
      "[14:07:45]  - Nível: image    | Status: Sucesso | Detalhe: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\ImageLevel_Ensemble_Models_soft_voting\\metrics_image_level_soft_voting.json\n",
      "[14:07:45]  - Nível: patient  | Status: Sucesso | Detalhe: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\tables\\Ensemble_Between_Models\\PatientLevel_Ensemble_soft_voting\\global_metrics_patient_level_soft_voting.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modules.runner_ma import run_ma_for_models_parallel\n",
    "from modules.utils import log \n",
    "\n",
    "\n",
    "# =======================================================================\n",
    "# 2. EXECUTE O PIPELINE\n",
    "# =======================================================================\n",
    "\n",
    "log(f'\\n[MA] Rodando ensemble entre modelos para os tipos: {ENSEMBLE_TYPE} ...')\n",
    "\n",
    "run_ma_for_models_parallel(\n",
    "    tables_dir=TABLES_DIR,\n",
    "    models_to_include=MODELS,\n",
    "    ensemble_type=ENSEMBLE_TYPE, \n",
    "    weight_metric=WEIGHT_METRIC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf3633",
   "metadata": {},
   "source": [
    "#### **[MA]  Gerar Métricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a45827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:58] [METRICS] Salvo: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\results\\MA\\tile\\metrics_tile_level_soft_voting.json\n",
      "[14:38:03] [METRICS] Salvo: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\results\\MA\\image\\metrics_image_level_soft_voting.json\n",
      "[14:38:04] [METRICS] Salvo: c:\\Users\\Fernando Alves\\Desktop\\Nova pasta\\ensamble_pipeline_MA_SA_models\\outputs\\results\\MA\\patient\\metrics_patient_level_soft_voting.json\n"
     ]
    }
   ],
   "source": [
    "generate_ma_metrics_from_tables()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
