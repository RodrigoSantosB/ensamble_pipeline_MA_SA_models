{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1175f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados do modelo SA\n",
    "path_sa = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\notebooks\\summary_results_effnet\\0618-231213_EFF-NET_fold5_results.csv'\n",
    "df_sa = pd.read_csv(path_sa)  \n",
    "\n",
    "# Extrair patient_id e tile_name do image_path no SA usando regex\n",
    "df_sa[['patient_id', 'tile_name']] = df_sa['image_path'].str.extract(r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)')\n",
    "\n",
    "# Parsear probability_vector e obter a probabilidade da classe verdadeira para SA\n",
    "df_sa['prob_vector_sa'] = df_sa['probability_vector'].apply(ast.literal_eval)\n",
    "df_sa['true_prob_sa'] = df_sa.apply(lambda row: row['prob_vector_sa'][row['true_label']], axis=1)\n",
    "\n",
    "# Agrupar por paciente e calcular a média da probabilidade da classe verdadeira\n",
    "sa_grouped = df_sa.groupby('patient_id')['true_prob_sa'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd94e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>true_prob_sa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-3M-AB46</td>\n",
       "      <td>0.792122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-3M-AB47</td>\n",
       "      <td>0.113637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-B7-A5TI</td>\n",
       "      <td>0.055886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-B7-A5TN</td>\n",
       "      <td>0.607237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-BR-4191</td>\n",
       "      <td>0.660522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>TCGA-RD-A8N2</td>\n",
       "      <td>0.048525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>TCGA-VQ-A8PB</td>\n",
       "      <td>0.123806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>TCGA-VQ-A8PF</td>\n",
       "      <td>0.504888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>TCGA-VQ-A8PX</td>\n",
       "      <td>0.086565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>TCGA-VQ-A927</td>\n",
       "      <td>0.392264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  true_prob_sa\n",
       "0   TCGA-3M-AB46      0.792122\n",
       "1   TCGA-3M-AB47      0.113637\n",
       "2   TCGA-B7-A5TI      0.055886\n",
       "3   TCGA-B7-A5TN      0.607237\n",
       "4   TCGA-BR-4191      0.660522\n",
       "..           ...           ...\n",
       "78  TCGA-RD-A8N2      0.048525\n",
       "79  TCGA-VQ-A8PB      0.123806\n",
       "80  TCGA-VQ-A8PF      0.504888\n",
       "81  TCGA-VQ-A8PX      0.086565\n",
       "82  TCGA-VQ-A927      0.392264\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e6a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_ma = r\"C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\tables\\MOBNet\\Ensemble_patient_level_soft_voting\\ensemble_per_patient_soft_voting.csv\"\n",
    "# Carregar os dados do modelo MA\n",
    "df_ma = pd.read_csv(path_ma)\n",
    "\n",
    "# Parsear mean_probs_per_class_paciente e obter a probabilidade da classe verdadeira para MA\n",
    "df_ma['prob_vector_ma'] = df_ma['mean_probs_per_class_paciente'].apply(ast.literal_eval)\n",
    "df_ma['true_prob_ma'] = df_ma.apply(lambda row: row['prob_vector_ma'][row['true_label']], axis=1)\n",
    "\n",
    "# Agrupar por paciente e calcular a média da probabilidade da classe verdadeira\n",
    "ma_grouped = df_ma.groupby('patient_id')['true_prob_ma'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd05e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>true_prob_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-3M-AB47</td>\n",
       "      <td>0.102192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-B7-A5TN</td>\n",
       "      <td>0.622546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-BR-4253</td>\n",
       "      <td>0.317639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-BR-4279</td>\n",
       "      <td>0.605457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-BR-4357</td>\n",
       "      <td>0.543170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TCGA-VQ-A8PX</td>\n",
       "      <td>0.314009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>TCGA-VQ-A91W</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>TCGA-VQ-A923</td>\n",
       "      <td>0.346083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>TCGA-VQ-A928</td>\n",
       "      <td>0.169799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>TCGA-VQ-AA69</td>\n",
       "      <td>0.246640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  true_prob_ma\n",
       "0   TCGA-3M-AB47      0.102192\n",
       "1   TCGA-B7-A5TN      0.622546\n",
       "2   TCGA-BR-4253      0.317639\n",
       "3   TCGA-BR-4279      0.605457\n",
       "4   TCGA-BR-4357      0.543170\n",
       "..           ...           ...\n",
       "77  TCGA-VQ-A8PX      0.314009\n",
       "78  TCGA-VQ-A91W      0.132300\n",
       "79  TCGA-VQ-A923      0.346083\n",
       "80  TCGA-VQ-A928      0.169799\n",
       "81  TCGA-VQ-AA69      0.246640\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0d73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unir os dataframes agrupados por patient_id\n",
    "df_common = pd.merge(sa_grouped, ma_grouped, on='patient_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9c5788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>true_prob_sa</th>\n",
       "      <th>true_prob_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-3M-AB47</td>\n",
       "      <td>0.113637</td>\n",
       "      <td>0.102192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-B7-A5TN</td>\n",
       "      <td>0.607237</td>\n",
       "      <td>0.622546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-BR-4253</td>\n",
       "      <td>0.179233</td>\n",
       "      <td>0.317639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-BR-4279</td>\n",
       "      <td>0.606522</td>\n",
       "      <td>0.605457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-BR-4361</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>0.321253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TCGA-BR-4370</td>\n",
       "      <td>0.299520</td>\n",
       "      <td>0.437798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TCGA-BR-7707</td>\n",
       "      <td>0.244372</td>\n",
       "      <td>0.251558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TCGA-BR-7715</td>\n",
       "      <td>0.670790</td>\n",
       "      <td>0.705697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TCGA-BR-7957</td>\n",
       "      <td>0.479163</td>\n",
       "      <td>0.394065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TCGA-BR-8590</td>\n",
       "      <td>0.450435</td>\n",
       "      <td>0.559958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TCGA-BR-8687</td>\n",
       "      <td>0.846977</td>\n",
       "      <td>0.734936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TCGA-BR-A4IZ</td>\n",
       "      <td>0.154114</td>\n",
       "      <td>0.289697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TCGA-CG-4443</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.609329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TCGA-CG-4444</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.611469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TCGA-CG-4462</td>\n",
       "      <td>0.057466</td>\n",
       "      <td>0.120077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TCGA-CG-4469</td>\n",
       "      <td>0.276286</td>\n",
       "      <td>0.625582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TCGA-D7-5578</td>\n",
       "      <td>0.538524</td>\n",
       "      <td>0.669570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCGA-D7-6519</td>\n",
       "      <td>0.337808</td>\n",
       "      <td>0.479830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TCGA-D7-6521</td>\n",
       "      <td>0.295440</td>\n",
       "      <td>0.543432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TCGA-D7-6822</td>\n",
       "      <td>0.667842</td>\n",
       "      <td>0.746625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TCGA-D7-8570</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.226782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TCGA-D7-A6F0</td>\n",
       "      <td>0.047261</td>\n",
       "      <td>0.485716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TCGA-D7-A6F2</td>\n",
       "      <td>0.575128</td>\n",
       "      <td>0.554015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TCGA-HU-A4GD</td>\n",
       "      <td>0.365063</td>\n",
       "      <td>0.649221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TCGA-HU-A4GU</td>\n",
       "      <td>0.158270</td>\n",
       "      <td>0.275028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TCGA-HU-A4H8</td>\n",
       "      <td>0.280553</td>\n",
       "      <td>0.176337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TCGA-MX-A5UG</td>\n",
       "      <td>0.113045</td>\n",
       "      <td>0.386387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TCGA-RD-A7BS</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.117152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TCGA-RD-A8N2</td>\n",
       "      <td>0.048525</td>\n",
       "      <td>0.489369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TCGA-VQ-A8PB</td>\n",
       "      <td>0.123806</td>\n",
       "      <td>0.357524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TCGA-VQ-A8PF</td>\n",
       "      <td>0.504888</td>\n",
       "      <td>0.219734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TCGA-VQ-A8PX</td>\n",
       "      <td>0.086565</td>\n",
       "      <td>0.314009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  true_prob_sa  true_prob_ma\n",
       "0   TCGA-3M-AB47      0.113637      0.102192\n",
       "1   TCGA-B7-A5TN      0.607237      0.622546\n",
       "2   TCGA-BR-4253      0.179233      0.317639\n",
       "3   TCGA-BR-4279      0.606522      0.605457\n",
       "4   TCGA-BR-4361      0.308012      0.321253\n",
       "5   TCGA-BR-4370      0.299520      0.437798\n",
       "6   TCGA-BR-7707      0.244372      0.251558\n",
       "7   TCGA-BR-7715      0.670790      0.705697\n",
       "8   TCGA-BR-7957      0.479163      0.394065\n",
       "9   TCGA-BR-8590      0.450435      0.559958\n",
       "10  TCGA-BR-8687      0.846977      0.734936\n",
       "11  TCGA-BR-A4IZ      0.154114      0.289697\n",
       "12  TCGA-CG-4443      0.630267      0.609329\n",
       "13  TCGA-CG-4444      0.726639      0.611469\n",
       "14  TCGA-CG-4462      0.057466      0.120077\n",
       "15  TCGA-CG-4469      0.276286      0.625582\n",
       "16  TCGA-D7-5578      0.538524      0.669570\n",
       "17  TCGA-D7-6519      0.337808      0.479830\n",
       "18  TCGA-D7-6521      0.295440      0.543432\n",
       "19  TCGA-D7-6822      0.667842      0.746625\n",
       "20  TCGA-D7-8570      0.158183      0.226782\n",
       "21  TCGA-D7-A6F0      0.047261      0.485716\n",
       "22  TCGA-D7-A6F2      0.575128      0.554015\n",
       "23  TCGA-HU-A4GD      0.365063      0.649221\n",
       "24  TCGA-HU-A4GU      0.158270      0.275028\n",
       "25  TCGA-HU-A4H8      0.280553      0.176337\n",
       "26  TCGA-MX-A5UG      0.113045      0.386387\n",
       "27  TCGA-RD-A7BS      0.029470      0.117152\n",
       "28  TCGA-RD-A8N2      0.048525      0.489369\n",
       "29  TCGA-VQ-A8PB      0.123806      0.357524\n",
       "30  TCGA-VQ-A8PF      0.504888      0.219734\n",
       "31  TCGA-VQ-A8PX      0.086565      0.314009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591c5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 1. Estatísticas Descritivas das Probabilidades da Classe Verdadeira por Paciente\n",
      "Modelo\tNúmero de Pacientes\tMédia\tDesvio Padrão\tMediana\tMínimo\tMáximo\n",
      "SA (EfficientNet)\t32\t0.3432\t0.2350\t0.2975\t0.0295\t0.8470\n",
      "MA (MobileNet Ensemble)\t32\t0.4375\t0.1944\t0.4588\t0.1022\t0.7466\n",
      "\n",
      "Tabela 2. Resultado do Teste de Wilcoxon Signed-Rank\n",
      "Estatística W\tValor-p\tSignificância Estatística (α = 0,05)\n",
      "105.0000\t0.00223\tSim\n",
      "\n",
      "Interpretação:\n",
      "Há uma diferença estatisticamente significativa entre os modelos (rejeitamos H0).\n",
      "O modelo MA (MobileNet ensemble) tem desempenho superior.\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há pacientes comuns\n",
    "if df_common.empty:\n",
    "    print(\"Não há pacientes comuns para comparação.\")\n",
    "else:\n",
    "    # Calcular estatísticas descritivas para a Tabela 1\n",
    "    sa_stats = {\n",
    "        'Número de Pacientes': len(df_common),\n",
    "        'Média': np.mean(df_common['true_prob_sa']),\n",
    "        'Desvio Padrão': np.std(df_common['true_prob_sa'], ddof=1),\n",
    "        'Mediana': np.median(df_common['true_prob_sa']),\n",
    "        'Mínimo': np.min(df_common['true_prob_sa']),\n",
    "        'Máximo': np.max(df_common['true_prob_sa'])\n",
    "    }\n",
    "    \n",
    "    ma_stats = {\n",
    "        'Número de Pacientes': len(df_common),\n",
    "        'Média': np.mean(df_common['true_prob_ma']),\n",
    "        'Desvio Padrão': np.std(df_common['true_prob_ma'], ddof=1),\n",
    "        'Mediana': np.median(df_common['true_prob_ma']),\n",
    "        'Mínimo': np.min(df_common['true_prob_ma']),\n",
    "        'Máximo': np.max(df_common['true_prob_ma'])\n",
    "    }\n",
    "    \n",
    "    # Aplicar o teste de Wilcoxon Signed-Rank Test\n",
    "    stat, p_value = wilcoxon(df_common['true_prob_sa'], df_common['true_prob_ma'])\n",
    "    \n",
    "    # Determinar significância estatística\n",
    "    alpha = 0.05\n",
    "    significancia = \"Sim\" if p_value < alpha else \"Não\"\n",
    "    \n",
    "    # Imprimir Tabela 1\n",
    "    print(\"Tabela 1. Estatísticas Descritivas das Probabilidades da Classe Verdadeira por Paciente\")\n",
    "    print(\"Modelo\\tNúmero de Pacientes\\tMédia\\tDesvio Padrão\\tMediana\\tMínimo\\tMáximo\")\n",
    "    print(f\"SA ({single_model})\\t{sa_stats['Número de Pacientes']}\\t{sa_stats['Média']:.4f}\\t{sa_stats['Desvio Padrão']:.4f}\\t{sa_stats['Mediana']:.4f}\\t{sa_stats['Mínimo']:.4f}\\t{sa_stats['Máximo']:.4f}\")\n",
    "    print(f\"MA (MobileNet Ensemble)\\t{ma_stats['Número de Pacientes']}\\t{ma_stats['Média']:.4f}\\t{ma_stats['Desvio Padrão']:.4f}\\t{ma_stats['Mediana']:.4f}\\t{ma_stats['Mínimo']:.4f}\\t{ma_stats['Máximo']:.4f}\")\n",
    "    \n",
    "    # Imprimir Tabela 2\n",
    "    print(\"\\nTabela 2. Resultado do Teste de Wilcoxon Signed-Rank\")\n",
    "    print(\"Estatística W\\tValor-p\\tSignificância Estatística (α = 0,05)\")\n",
    "    print(f\"{stat:.4f}\\t{p_value:.5f}\\t{significancia}\")\n",
    "    \n",
    "    # Interpretação adicional\n",
    "    print(f\"\\nInterpretação:\")\n",
    "    if p_value < alpha:\n",
    "        print(\"Há uma diferença estatisticamente significativa entre os modelos (rejeitamos H0).\")\n",
    "        if sa_stats['Média'] > ma_stats['Média']:\n",
    "            print(f\"O modelo SA ({single_model}) tem desempenho superior.\")\n",
    "        else:\n",
    "            print(\"O modelo MA (MobileNet ensemble) tem desempenho superior.\")\n",
    "    else:\n",
    "        print(\"Não há diferença estatisticamente significativa entre os modelos (não rejeitamos H0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b068c",
   "metadata": {},
   "source": [
    "## **Por Paciente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1b64ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a400c",
   "metadata": {},
   "source": [
    "### **Funções Uteis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "491c8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar os dados do SA (EffNet)\n",
    "def process_sa_data(folds_dir):\n",
    "    \"\"\"Processa todos os folds do modelo SA e retorna um DataFrame consolidado\"\"\"\n",
    "    all_sa_data = []\n",
    "    \n",
    "    # Listar todos os arquivos de fold\n",
    "    fold_files = [f for f in os.listdir(folds_dir) if f.endswith('_results.csv')]\n",
    "    \n",
    "    for fold_file in fold_files:\n",
    "        fold_path = os.path.join(folds_dir, fold_file)\n",
    "        df_fold = pd.read_csv(fold_path)\n",
    "        \n",
    "        # Extrair patient_id e tile_name usando regex\n",
    "        df_fold[['patient_id', 'tile_name']] = df_fold['image_path'].str.extract(\n",
    "            r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "        )\n",
    "        \n",
    "        # Parsear probability_vector e obter a probabilidade da classe verdadeira\n",
    "        df_fold['prob_vector'] = df_fold['probability_vector'].apply(ast.literal_eval)\n",
    "        df_fold['true_prob'] = df_fold.apply(\n",
    "            lambda row: row['prob_vector'][row['true_label']], axis=1\n",
    "        )\n",
    "        \n",
    "        # Adicionar identificador do fold\n",
    "        df_fold['fold'] = fold_file.split('_fold')[1].split('_')[0]\n",
    "        \n",
    "        all_sa_data.append(df_fold)\n",
    "    \n",
    "    # Consolidar todos os dados\n",
    "    df_sa = pd.concat(all_sa_data, ignore_index=True)\n",
    "    return df_sa\n",
    "\n",
    "# Função para construir a tabela ensemble a partir das três arquiteturas\n",
    "def build_ensemble_table(models_dir):\n",
    "    \"\"\"Constrói a tabela ensemble a partir dos arquivos das três arquiteturas\"\"\"\n",
    "    # Mapeamento de arquiteturas e seus prefixos\n",
    "    architectures = {\n",
    "        'gg': {'file': 'merged_table_gg.csv', 'prefix': 'g'},\n",
    "        'mob': {'file': 'merged_table_mob.csv', 'prefix': 'm'}, \n",
    "        'sh': {'file': 'merged_table_sh.csv', 'prefix': 's'}\n",
    "    }\n",
    "    \n",
    "    # Carregar e processar cada arquitetura\n",
    "    all_models_data = []\n",
    "    \n",
    "    for arch_name, arch_info in architectures.items():\n",
    "        file_path = os.path.join(models_dir, arch_info['file'])\n",
    "        prefix = arch_info['prefix']\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Processando {arch_name}...\")\n",
    "            df_arch = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extrair patient_id e tile_name\n",
    "            df_arch[['patient_id', 'tile_name']] = df_arch['image_path'].str.extract(\n",
    "                r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "            )\n",
    "            \n",
    "            # Para cada fold (0 a 9) na arquitetura, extrair probabilidades\n",
    "            for i in range(10):\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    df_arch[prob_col] = df_arch[prob_col].apply(ast.literal_eval)\n",
    "            \n",
    "            all_models_data.append(df_arch)\n",
    "    \n",
    "    # Combinar todos os dados\n",
    "    if not all_models_data:\n",
    "        raise ValueError(\"Nenhum dado de arquitetura foi encontrado\")\n",
    "    \n",
    "    # Usar o primeiro DataFrame como base\n",
    "    df_ensemble = all_models_data[0][['patient_id', 'tile_name', 'true_label']].copy()\n",
    "    \n",
    "    # Coletar todas as probabilidades de todos os modelos\n",
    "    all_probs = []\n",
    "    for df_arch in all_models_data:\n",
    "        for i in range(10):\n",
    "            for prefix in ['g', 'm', 's']:\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    # Adicionar as probabilidades desta coluna\n",
    "                    probs_series = df_arch[prob_col].apply(\n",
    "                        lambda x: x if isinstance(x, dict) else {}\n",
    "                    )\n",
    "                    all_probs.append(probs_series)\n",
    "    \n",
    "    # Calcular probabilidades médias por classe para cada tile\n",
    "    print(\"Calculando probabilidades médias...\")\n",
    "    mean_probs_list = []\n",
    "    true_probs_list = []\n",
    "    predicted_labels_list = []\n",
    "    predicted_probs_list = []\n",
    "    \n",
    "    for idx in range(len(df_ensemble)):\n",
    "        # Coletar todas as probabilidades para este tile\n",
    "        tile_probs = []\n",
    "        for probs_series in all_probs:\n",
    "            if idx < len(probs_series) and probs_series.iloc[idx]:\n",
    "                tile_probs.append(probs_series.iloc[idx])\n",
    "        \n",
    "        if tile_probs:\n",
    "            # Calcular médias por classe\n",
    "            mean_probs = {\n",
    "                'cin': np.mean([p.get('cin', 0) for p in tile_probs]),\n",
    "                'ebv': np.mean([p.get('ebv', 0) for p in tile_probs]),\n",
    "                'msi': np.mean([p.get('msi', 0) for p in tile_probs]),\n",
    "                'gs': np.mean([p.get('gs', 0) for p in tile_probs])\n",
    "            }\n",
    "            \n",
    "            # Determinar label predito\n",
    "            predicted_label = max(mean_probs, key=mean_probs.get)\n",
    "            predicted_prob = mean_probs[predicted_label]\n",
    "            \n",
    "            # Obter a true_label\n",
    "            true_label = df_ensemble.iloc[idx]['true_label']\n",
    "            true_prob = mean_probs.get(true_label, 0)\n",
    "            \n",
    "            mean_probs_list.append(mean_probs)\n",
    "            true_probs_list.append(true_prob)\n",
    "            predicted_labels_list.append(predicted_label)\n",
    "            predicted_probs_list.append(predicted_prob)\n",
    "        else:\n",
    "            # Caso não haja probabilidades para este tile\n",
    "            mean_probs_list.append({})\n",
    "            true_probs_list.append(0)\n",
    "            predicted_labels_list.append('')\n",
    "            predicted_probs_list.append(0)\n",
    "    \n",
    "    # Adicionar colunas ao DataFrame ensemble\n",
    "    df_ensemble['mean_probs_per_class_tile'] = mean_probs_list\n",
    "    df_ensemble['true_prob'] = true_probs_list\n",
    "    df_ensemble['predicted_label'] = predicted_labels_list\n",
    "    df_ensemble['predicted_probability'] = predicted_probs_list\n",
    "    \n",
    "    return df_ensemble\n",
    "\n",
    "# Função para calcular métricas por classe\n",
    "def calculate_metrics_per_class(df):\n",
    "    \"\"\"Calcula métricas de desempenho por classe\"\"\"\n",
    "    # Calcular métricas por classe\n",
    "    class_report = classification_report(\n",
    "        df['true_label'], \n",
    "        df['predicted_label'], \n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Extrair métricas para cada classe\n",
    "    metrics_per_class = {}\n",
    "    classes = ['cin', 'ebv', 'msi', 'gs']\n",
    "    \n",
    "    for cls in classes:\n",
    "        if cls in class_report:\n",
    "            metrics_per_class[cls] = {\n",
    "                'precision': class_report[cls]['precision'],\n",
    "                'recall': class_report[cls]['recall'],\n",
    "                'f1': class_report[cls]['f1-score'],\n",
    "                'support': class_report[cls]['support']\n",
    "            }\n",
    "    \n",
    "    # Calcular métricas weighted average\n",
    "    metrics_per_class['weighted'] = {\n",
    "        'precision': class_report['weighted avg']['precision'],\n",
    "        'recall': class_report['weighted avg']['recall'],\n",
    "        'f1': class_report['weighted avg']['f1-score'],\n",
    "        'support': class_report['weighted avg']['support']\n",
    "    }\n",
    "    \n",
    "    # Calcular acurácia geral\n",
    "    accuracy = class_report['accuracy']\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'metrics_per_class': metrics_per_class\n",
    "    }\n",
    "\n",
    "# Função para calcular métricas com bootstrapping\n",
    "def calculate_metrics_with_bootstrapping(df, n_bootstraps=100):\n",
    "    \"\"\"Calcula métricas usando bootstrapping para estimar variabilidade\"\"\"\n",
    "    bootstrap_metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision_cin': [], 'precision_ebv': [], 'precision_msi': [], 'precision_gs': [], 'precision_weighted': [],\n",
    "        'recall_cin': [], 'recall_ebv': [], 'recall_msi': [], 'recall_gs': [], 'recall_weighted': [],\n",
    "        'f1_cin': [], 'f1_ebv': [], 'f1_msi': [], 'f1_gs': [], 'f1_weighted': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Amostra bootstrap com reposição\n",
    "        bootstrap_sample = resample(df, replace=True, random_state=_)\n",
    "        \n",
    "        # Calcular métricas para a amostra bootstrap\n",
    "        metrics = calculate_metrics_per_class(bootstrap_sample)\n",
    "        \n",
    "        # Armazenar métricas\n",
    "        bootstrap_metrics['accuracy'].append(metrics['accuracy'])\n",
    "        \n",
    "        for cls in ['cin', 'ebv', 'msi', 'gs', 'weighted']:\n",
    "            if cls in metrics['metrics_per_class']:\n",
    "                bootstrap_metrics[f'precision_{cls}'].append(metrics['metrics_per_class'][cls]['precision'])\n",
    "                bootstrap_metrics[f'recall_{cls}'].append(metrics['metrics_per_class'][cls]['recall'])\n",
    "                bootstrap_metrics[f'f1_{cls}'].append(metrics['metrics_per_class'][cls]['f1'])\n",
    "    \n",
    "    # Calcular médias e desvios padrão\n",
    "    result = {}\n",
    "    for metric, values in bootstrap_metrics.items():\n",
    "        if values:  # Verificar se a lista não está vazia\n",
    "            result[f'{metric}_mean'] = np.mean(values)\n",
    "            result[f'{metric}_std'] = np.std(values, ddof=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Função para calcular métricas por paciente\n",
    "def calculate_metrics_per_patient(df, model_name):\n",
    "    \"\"\"Calcula métricas de desempenho agrupadas por paciente\"\"\"\n",
    "    grouped = df.groupby('patient_id')\n",
    "    \n",
    "    results = []\n",
    "    for patient, group in grouped:\n",
    "        # Calcular acurácia\n",
    "        accuracy = np.mean(group['true_label'] == group['predicted_label'])\n",
    "        \n",
    "        # Calcular precision, recall e f1 (usando weighted average)\n",
    "        from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "        \n",
    "        # Para multi-classe, precisamos garantir que todas as classes estejam representadas\n",
    "        unique_classes = list(set(group['true_label'].unique()) | set(group['predicted_label'].unique()))\n",
    "        precision = precision_score(group['true_label'], group['predicted_label'], \n",
    "                                  average='weighted', zero_division=0, labels=unique_classes)\n",
    "        recall = recall_score(group['true_label'], group['predicted_label'], \n",
    "                             average='weighted', zero_division=0, labels=unique_classes)\n",
    "        f1 = f1_score(group['true_label'], group['predicted_label'], \n",
    "                     average='weighted', zero_division=0, labels=unique_classes)\n",
    "        \n",
    "        # Calcular a média da probabilidade da classe verdadeira\n",
    "        mean_true_prob = group['true_prob'].mean()\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': patient,\n",
    "            f'accuracy_{model_name}': accuracy,\n",
    "            f'precision_{model_name}': precision,\n",
    "            f'recall_{model_name}': recall,\n",
    "            f'f1_{model_name}': f1,\n",
    "            f'true_prob_{model_name}': mean_true_prob\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a1e084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "SA_FOLDS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\notebooks\\summary_results_effnet'\n",
    "MA_MODELS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models'\n",
    "N_BOOTSTRAPS = 100  # Número de amostras bootstrap para calcular o desvio padrão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a94666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dados do SA (EffNet)...\n",
      "Construindo tabela ensemble do MA...\n",
      "Processando gg...\n",
      "Processando mob...\n",
      "Processando sh...\n",
      "Calculando probabilidades médias...\n",
      "Calculando métricas com bootstrapping para o SA...\n",
      "Calculando métricas com bootstrapping para o MA...\n",
      "Calculando métricas por paciente para o teste de Wilcoxon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando Alves\\anaconda3\\envs\\redes\\lib\\site-packages\\scipy\\stats\\_wilcoxon.py:172: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = (r_plus - mn) / se\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tabela para Precision ===\n",
      "Class\tSA (EffNet)\tMA (Ensemble)\n",
      "cin\t0.5388 ± 0.0006\t0.6248 ± 0.0014\n",
      "ebv\t0.1030 ± 0.0007\t0.6242 ± 0.0037\n",
      "msi\t0.3844 ± 0.0008\t0.6450 ± 0.0038\n",
      "gs\t0.1650 ± 0.0008\t0.3362 ± 0.0027\n",
      "weighted\t0.3840 ± 0.0005\t0.5853 ± 0.0013\n",
      "Tabela precision salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\precision_per_class_comparison_with_std.csv\n",
      "\n",
      "=== Tabela para Recall ===\n",
      "Class\tSA (EffNet)\tMA (Ensemble)\n",
      "cin\t0.5968 ± 0.0005\t0.8048 ± 0.0014\n",
      "ebv\t0.0957 ± 0.0007\t0.3906 ± 0.0030\n",
      "msi\t0.3739 ± 0.0007\t0.2819 ± 0.0023\n",
      "gs\t0.1305 ± 0.0006\t0.3970 ± 0.0031\n",
      "weighted\t0.4014 ± 0.0004\t0.5751 ± 0.0011\n",
      "Tabela recall salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\recall_per_class_comparison_with_std.csv\n",
      "\n",
      "=== Tabela para F1 ===\n",
      "Class\tSA (EffNet)\tMA (Ensemble)\n",
      "cin\t0.5663 ± 0.0005\t0.7035 ± 0.0012\n",
      "ebv\t0.0992 ± 0.0007\t0.4805 ± 0.0029\n",
      "msi\t0.3791 ± 0.0006\t0.3923 ± 0.0026\n",
      "gs\t0.1458 ± 0.0007\t0.3641 ± 0.0026\n",
      "weighted\t0.3917 ± 0.0004\t0.5554 ± 0.0012\n",
      "Tabela f1 salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\f1_per_class_comparison_with_std.csv\n",
      "\n",
      "=== Acurácia ===\n",
      "SA (EffNet) Acurácia: 0.4014 ± 0.0004\n",
      "MA (Ensemble) Acurácia: 0.5751 ± 0.0011\n",
      "Tabela de acurácia salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\accuracy_comparison_with_std.csv\n",
      "\n",
      "=== Resultados do Teste de Wilcoxon Signed-Rank ===\n",
      "Métrica\tEstatística W\tValor-p\tSignificância Estatística (α = 0,05)\n",
      "accuracy\t114.0000\t0.00413\tSim\n",
      "precision\t0.0000\tnan\tNão\n",
      "recall\t114.0000\t0.00413\tSim\n",
      "f1\t154.0000\t0.03943\tSim\n",
      "true_prob\t214.0000\t0.35954\tNão\n",
      "\n",
      "Interpretação:\n",
      "O modelo MA (Multi-Architecture) tem desempenho significativamente melhor em accuracy.\n",
      "Não há diferença estatisticamente significativa entre os modelos em precision.\n",
      "O modelo MA (Multi-Architecture) tem desempenho significativamente melhor em recall.\n",
      "O modelo MA (Multi-Architecture) tem desempenho significativamente melhor em f1.\n",
      "Não há diferença estatisticamente significativa entre os modelos em true_prob.\n",
      "\n",
      "Tabela ensemble salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\ensemble_per_tile_soft_voting.csv\n",
      "\n",
      "=== Relatório Completo ===\n",
      "Métrica\tClasse\tSA (EffNet)\tMA (Ensemble)\n",
      "precision\tcin\t0.5388 ± 0.0006\t0.6248 ± 0.0014\n",
      "precision\tebv\t0.1030 ± 0.0007\t0.6242 ± 0.0037\n",
      "precision\tmsi\t0.3844 ± 0.0008\t0.6450 ± 0.0038\n",
      "precision\tgs\t0.1650 ± 0.0008\t0.3362 ± 0.0027\n",
      "precision\tweighted\t0.3840 ± 0.0005\t0.5853 ± 0.0013\n",
      "recall\tcin\t0.5968 ± 0.0005\t0.8048 ± 0.0014\n",
      "recall\tebv\t0.0957 ± 0.0007\t0.3906 ± 0.0030\n",
      "recall\tmsi\t0.3739 ± 0.0007\t0.2819 ± 0.0023\n",
      "recall\tgs\t0.1305 ± 0.0006\t0.3970 ± 0.0031\n",
      "recall\tweighted\t0.4014 ± 0.0004\t0.5751 ± 0.0011\n",
      "f1\tcin\t0.5663 ± 0.0005\t0.7035 ± 0.0012\n",
      "f1\tebv\t0.0992 ± 0.0007\t0.4805 ± 0.0029\n",
      "f1\tmsi\t0.3791 ± 0.0006\t0.3923 ± 0.0026\n",
      "f1\tgs\t0.1458 ± 0.0007\t0.3641 ± 0.0026\n",
      "f1\tweighted\t0.3917 ± 0.0004\t0.5554 ± 0.0012\n",
      "accuracy\toverall\t0.4014 ± 0.0004\t0.5751 ± 0.0011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Processar dados\n",
    "print(\"Processando dados do SA (EffNet)...\")\n",
    "df_sa = process_sa_data(SA_FOLDS_DIR)\n",
    "\n",
    "print(\"Construindo tabela ensemble do MA...\")\n",
    "df_ma = build_ensemble_table(MA_MODELS_DIR)\n",
    "\n",
    "# Calcular métricas com bootstrapping para o SA\n",
    "print(\"Calculando métricas com bootstrapping para o SA...\")\n",
    "sa_bootstrap_metrics = calculate_metrics_with_bootstrapping(df_sa, N_BOOTSTRAPS)\n",
    "\n",
    "# Calcular métricas com bootstrapping para o MA\n",
    "print(\"Calculando métricas com bootstrapping para o MA...\")\n",
    "ma_bootstrap_metrics = calculate_metrics_with_bootstrapping(df_ma, N_BOOTSTRAPS)\n",
    "\n",
    "# Calcular métricas por paciente para o teste de Wilcoxon\n",
    "print(\"Calculando métricas por paciente para o teste de Wilcoxon...\")\n",
    "sa_patient_metrics = calculate_metrics_per_patient(df_sa, 'sa')\n",
    "ma_patient_metrics = calculate_metrics_per_patient(df_ma, 'ma')\n",
    "\n",
    "# Unir os dataframes por patient_id\n",
    "df_common = pd.merge(sa_patient_metrics, ma_patient_metrics, on='patient_id', how='inner')\n",
    "\n",
    "# Verificar se há pacientes comuns\n",
    "if df_common.empty:\n",
    "    print(\"Não há pacientes comuns para comparação.\")\n",
    "else:\n",
    "    # Lista de métricas para comparar\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'true_prob']\n",
    "    \n",
    "    # Dicionário para armazenar resultados do Wilcoxon\n",
    "    wilcoxon_results = {}\n",
    "    \n",
    "    # Aplicar o teste de Wilcoxon para cada métrica\n",
    "    for metric in metrics:\n",
    "        stat, p_value = wilcoxon(df_common[f'{metric}_sa'], df_common[f'{metric}_ma'])\n",
    "        wilcoxon_results[metric] = {\n",
    "            'statistic': stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "    \n",
    "    # Calcular estatísticas descritivas para cada métrica\n",
    "    descriptive_stats = {}\n",
    "    for metric in metrics:\n",
    "        descriptive_stats[metric] = {\n",
    "            'sa_mean': np.mean(df_common[f'{metric}_sa']),\n",
    "            'sa_std': np.std(df_common[f'{metric}_sa'], ddof=1),\n",
    "            'ma_mean': np.mean(df_common[f'{metric}_ma']),\n",
    "            'ma_std': np.std(df_common[f'{metric}_ma'], ddof=1),\n",
    "        }\n",
    "\n",
    "# Gerar tabelas para cada métrica (Precision, Recall, F1)\n",
    "metrics_to_analyze = ['precision', 'recall', 'f1']\n",
    "classes = ['cin', 'ebv', 'msi', 'gs', 'weighted']\n",
    "\n",
    "for metric in metrics_to_analyze:\n",
    "    print(f\"\\n=== Tabela para {metric.capitalize()} ===\")\n",
    "    print(\"Class\\tSA (EffNet)\\tMA (Ensemble)\")\n",
    "    \n",
    "    for cls in classes:\n",
    "        sa_mean = sa_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        sa_std = sa_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        ma_mean = ma_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        ma_std = ma_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        \n",
    "        if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "            print(f\"{cls}\\t{sa_mean:.4f} ± {sa_std:.4f}\\t{ma_mean:.4f} ± {ma_std:.4f}\")\n",
    "    \n",
    "    # Criar DataFrame para exportação\n",
    "    export_data = []\n",
    "    for cls in classes:\n",
    "        sa_mean = sa_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        sa_std = sa_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        ma_mean = ma_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        ma_std = ma_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        \n",
    "        if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "            export_data.append({\n",
    "                'Class': cls,\n",
    "                'SA_Mean': sa_mean,\n",
    "                'SA_Std': sa_std,\n",
    "                'SA_Formatted': f\"{sa_mean:.4f} ± {sa_std:.4f}\",\n",
    "                'MA_Mean': ma_mean,\n",
    "                'MA_Std': ma_std,\n",
    "                'MA_Formatted': f\"{ma_mean:.4f} ± {ma_std:.4f}\"\n",
    "            })\n",
    "    \n",
    "    export_df = pd.DataFrame(export_data)\n",
    "    \n",
    "    # Salvar tabela\n",
    "    output_path = os.path.join(MA_MODELS_DIR, f'{metric}_per_class_comparison_with_std.csv')\n",
    "    export_df.to_csv(output_path, index=False)\n",
    "    print(f\"Tabela {metric} salva em: {output_path}\")\n",
    "\n",
    "# Calcular e exibir acurácia\n",
    "print(\"\\n=== Acurácia ===\")\n",
    "sa_accuracy_mean = sa_bootstrap_metrics.get('accuracy_mean', np.nan)\n",
    "sa_accuracy_std = sa_bootstrap_metrics.get('accuracy_std', np.nan)\n",
    "ma_accuracy_mean = ma_bootstrap_metrics.get('accuracy_mean', np.nan)\n",
    "ma_accuracy_std = ma_bootstrap_metrics.get('accuracy_std', np.nan)\n",
    "\n",
    "if not np.isnan(sa_accuracy_mean) and not np.isnan(ma_accuracy_mean):\n",
    "    print(f\"SA (EffNet) Acurácia: {sa_accuracy_mean:.4f} ± {sa_accuracy_std:.4f}\")\n",
    "    print(f\"MA (Ensemble) Acurácia: {ma_accuracy_mean:.4f} ± {ma_accuracy_std:.4f}\")\n",
    "\n",
    "    # Salvar tabela de acurácia\n",
    "    accuracy_df = pd.DataFrame({\n",
    "        'Model': ['SA (EffNet)', 'MA (Ensemble)'],\n",
    "        'Accuracy_Mean': [sa_accuracy_mean, ma_accuracy_mean],\n",
    "        'Accuracy_Std': [sa_accuracy_std, ma_accuracy_std],\n",
    "        'Formatted': [\n",
    "            f\"{sa_accuracy_mean:.4f} ± {sa_accuracy_std:.4f}\",\n",
    "            f\"{ma_accuracy_mean:.4f} ± {ma_accuracy_std:.4f}\"\n",
    "        ]\n",
    "    })\n",
    "    accuracy_output_path = os.path.join(MA_MODELS_DIR, 'accuracy_comparison_with_std.csv')\n",
    "    accuracy_df.to_csv(accuracy_output_path, index=False)\n",
    "    print(f\"Tabela de acurácia salva em: {accuracy_output_path}\")\n",
    "\n",
    "# Resultados do teste de Wilcoxon\n",
    "if not df_common.empty:\n",
    "    print(\"\\n=== Resultados do Teste de Wilcoxon Signed-Rank ===\")\n",
    "    print(\"Métrica\\tEstatística W\\tValor-p\\tSignificância Estatística (α = 0,05)\")\n",
    "    for metric in metrics:\n",
    "        sig = \"Sim\" if wilcoxon_results[metric]['significant'] else \"Não\"\n",
    "        print(f\"{metric}\\t{wilcoxon_results[metric]['statistic']:.4f}\\t{wilcoxon_results[metric]['p_value']:.5f}\\t{sig}\")\n",
    "    \n",
    "    # Interpretação adicional\n",
    "    print(f\"\\nInterpretação:\")\n",
    "    for metric in metrics:\n",
    "        if wilcoxon_results[metric]['p_value'] < 0.05:\n",
    "            if descriptive_stats[metric]['sa_mean'] > descriptive_stats[metric]['ma_mean']:\n",
    "                print(f\"O modelo SA (EffNet) tem desempenho significativamente melhor em {metric}.\")\n",
    "            else:\n",
    "                print(f\"O modelo MA (Multi-Architecture) tem desempenho significativamente melhor em {metric}.\")\n",
    "        else:\n",
    "            print(f\"Não há diferença estatisticamente significativa entre os modelos em {metric}.\")\n",
    "\n",
    "# Salvar a tabela ensemble para uso futuro\n",
    "ensemble_output_path = os.path.join(MA_MODELS_DIR, 'ensemble_per_tile_soft_voting.csv')\n",
    "df_ma.to_csv(ensemble_output_path, index=False)\n",
    "print(f\"\\nTabela ensemble salva em: {ensemble_output_path}\")\n",
    "\n",
    "# Gerar relatório completo\n",
    "print(\"\\n=== Relatório Completo ===\")\n",
    "print(\"Métrica\\tClasse\\tSA (EffNet)\\tMA (Ensemble)\")\n",
    "\n",
    "for metric in metrics_to_analyze:\n",
    "    for cls in classes:\n",
    "        sa_mean = sa_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        sa_std = sa_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        ma_mean = ma_bootstrap_metrics.get(f'{metric}_{cls}_mean', np.nan)\n",
    "        ma_std = ma_bootstrap_metrics.get(f'{metric}_{cls}_std', np.nan)\n",
    "        \n",
    "        if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "            print(f\"{metric}\\t{cls}\\t{sa_mean:.4f} ± {sa_std:.4f}\\t{ma_mean:.4f} ± {ma_std:.4f}\")\n",
    "\n",
    "if not np.isnan(sa_accuracy_mean) and not np.isnan(ma_accuracy_mean):\n",
    "    print(f\"accuracy\\toverall\\t{sa_accuracy_mean:.4f} ± {sa_accuracy_std:.4f}\\t{ma_accuracy_mean:.4f} ± {ma_accuracy_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee2ee774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurações\n",
    "SA_FOLDS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\notebooks\\summary_results_effnet'\n",
    "MA_MODELS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c4b6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar os dados do SA (EffNet)\n",
    "def process_sa_data(folds_dir):\n",
    "    \"\"\"Processa todos os folds do modelo SA e retorna um DataFrame consolidado\"\"\"\n",
    "    all_sa_data = []\n",
    "    \n",
    "    # Listar todos os arquivos de fold\n",
    "    fold_files = [f for f in os.listdir(folds_dir) if f.endswith('_results.csv')]\n",
    "    \n",
    "    for fold_file in fold_files:\n",
    "        fold_path = os.path.join(folds_dir, fold_file)\n",
    "        df_fold = pd.read_csv(fold_path)\n",
    "        \n",
    "        # Extrair patient_id e tile_name usando regex\n",
    "        df_fold[['patient_id', 'tile_name']] = df_fold['image_path'].str.extract(\n",
    "            r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "        )\n",
    "        \n",
    "        # Parsear probability_vector e obter a probabilidade da classe verdadeira\n",
    "        df_fold['prob_vector'] = df_fold['probability_vector'].apply(ast.literal_eval)\n",
    "        df_fold['true_prob'] = df_fold.apply(\n",
    "            lambda row: row['prob_vector'][row['true_label']], axis=1\n",
    "        )\n",
    "        \n",
    "        # Adicionar identificador do fold\n",
    "        df_fold['fold'] = fold_file.split('_fold')[1].split('_')[0]\n",
    "        \n",
    "        all_sa_data.append(df_fold)\n",
    "    \n",
    "    # Consolidar todos os dados\n",
    "    df_sa = pd.concat(all_sa_data, ignore_index=True)\n",
    "    return df_sa\n",
    "\n",
    "# Função para construir a tabela ensemble a partir das três arquiteturas\n",
    "def build_ensemble_table(models_dir):\n",
    "    \"\"\"Constrói a tabela ensemble a partir dos arquivos das três arquiteturas\"\"\"\n",
    "    # Mapeamento de arquiteturas e seus prefixos\n",
    "    architectures = {\n",
    "        'gg': {'file': 'merged_table_gg.csv', 'prefix': 'g'},\n",
    "        'mob': {'file': 'merged_table_mob.csv', 'prefix': 'm'}, \n",
    "        'sh': {'file': 'merged_table_sh.csv', 'prefix': 's'}\n",
    "    }\n",
    "    \n",
    "    # Carregar e processar cada arquitetura\n",
    "    all_models_data = []\n",
    "    \n",
    "    for arch_name, arch_info in architectures.items():\n",
    "        file_path = os.path.join(models_dir, arch_info['file'])\n",
    "        prefix = arch_info['prefix']\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Processando {arch_name}...\")\n",
    "            df_arch = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extrair patient_id e tile_name\n",
    "            df_arch[['patient_id', 'tile_name']] = df_arch['image_path'].str.extract(\n",
    "                r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "            )\n",
    "            \n",
    "            # Para cada fold (0 a 9) na arquitetura, extrair probabilidades\n",
    "            for i in range(10):\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    df_arch[prob_col] = df_arch[prob_col].apply(ast.literal_eval)\n",
    "            \n",
    "            all_models_data.append(df_arch)\n",
    "    \n",
    "    # Combinar todos os dados\n",
    "    if not all_models_data:\n",
    "        raise ValueError(\"Nenhum dado de arquitetura foi encontrado\")\n",
    "    \n",
    "    # Usar o primeiro DataFrame como base\n",
    "    df_ensemble = all_models_data[0][['patient_id', 'tile_name', 'true_label']].copy()\n",
    "    \n",
    "    # Coletar todas as probabilidades de todos os modelos\n",
    "    all_probs = []\n",
    "    for df_arch in all_models_data:\n",
    "        for i in range(10):\n",
    "            for prefix in ['g', 'm', 's']:\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    # Adicionar as probabilidades desta coluna\n",
    "                    probs_series = df_arch[prob_col].apply(\n",
    "                        lambda x: x if isinstance(x, dict) else {}\n",
    "                    )\n",
    "                    all_probs.append(probs_series)\n",
    "    \n",
    "    # Calcular probabilidades médias por classe para cada tile\n",
    "    print(\"Calculando probabilidades médias...\")\n",
    "    mean_probs_list = []\n",
    "    true_probs_list = []\n",
    "    predicted_labels_list = []\n",
    "    predicted_probs_list = []\n",
    "    \n",
    "    for idx in range(len(df_ensemble)):\n",
    "        # Coletar todas as probabilidades para este tile\n",
    "        tile_probs = []\n",
    "        for probs_series in all_probs:\n",
    "            if idx < len(probs_series) and probs_series.iloc[idx]:\n",
    "                tile_probs.append(probs_series.iloc[idx])\n",
    "        \n",
    "        if tile_probs:\n",
    "            # Calcular médias por classe\n",
    "            mean_probs = {\n",
    "                'cin': np.mean([p.get('cin', 0) for p in tile_probs]),\n",
    "                'ebv': np.mean([p.get('ebv', 0) for p in tile_probs]),\n",
    "                'msi': np.mean([p.get('msi', 0) for p in tile_probs]),\n",
    "                'gs': np.mean([p.get('gs', 0) for p in tile_probs])\n",
    "            }\n",
    "            \n",
    "            # Determinar label predito\n",
    "            predicted_label = max(mean_probs, key=mean_probs.get)\n",
    "            predicted_prob = mean_probs[predicted_label]\n",
    "            \n",
    "            # Obter a true_label\n",
    "            true_label = df_ensemble.iloc[idx]['true_label']\n",
    "            true_prob = mean_probs.get(true_label, 0)\n",
    "            \n",
    "            mean_probs_list.append(mean_probs)\n",
    "            true_probs_list.append(true_prob)\n",
    "            predicted_labels_list.append(predicted_label)\n",
    "            predicted_probs_list.append(predicted_prob)\n",
    "        else:\n",
    "            # Caso não haja probabilidades para este tile\n",
    "            mean_probs_list.append({})\n",
    "            true_probs_list.append(0)\n",
    "            predicted_labels_list.append('')\n",
    "            predicted_probs_list.append(0)\n",
    "    \n",
    "    # Adicionar colunas ao DataFrame ensemble\n",
    "    df_ensemble['mean_probs_per_class_tile'] = mean_probs_list\n",
    "    df_ensemble['true_prob'] = true_probs_list\n",
    "    df_ensemble['predicted_label'] = predicted_labels_list\n",
    "    df_ensemble['predicted_probability'] = predicted_probs_list\n",
    "    \n",
    "    return df_ensemble\n",
    "\n",
    "# Função para calcular métricas a nível de tile\n",
    "def calculate_tile_level_metrics(df, model_name):\n",
    "    \"\"\"Calcula métricas de desempenho a nível de tile\"\"\"\n",
    "    # Para cada tile, determinar se a previsão está correta\n",
    "    df['correct'] = df['true_label'] == df['predicted_label']\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = np.mean(df['correct'])\n",
    "    \n",
    "    # Calcular precision, recall e f1\n",
    "    precision = precision_score(df['true_label'], df['predicted_label'], \n",
    "                              average='weighted', zero_division=0)\n",
    "    recall = recall_score(df['true_label'], df['predicted_label'], \n",
    "                         average='weighted', zero_division=0)\n",
    "    f1 = f1_score(df['true_label'], df['predicted_label'], \n",
    "                 average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calcular a média da probabilidade da classe verdadeira\n",
    "    mean_true_prob = df['true_prob'].mean()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'true_prob': mean_true_prob,\n",
    "        'tile_count': len(df)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3057353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para formatar valores\n",
    "def format_value(value, format_str=\"{:.4f}\"):\n",
    "    if isinstance(value, (int, float, np.number)):\n",
    "        return format_str.format(value)\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Função específica para formatar valor-p com mais casas decimais\n",
    "def format_p_value(value):\n",
    "    if isinstance(value, (int, float, np.number)):\n",
    "        return \"{:.6f}\".format(value)\n",
    "    else:\n",
    "        return str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d8430b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\t\t0.1071 ± 0.1764\t0.2680 ± 0.1781\t64673041.0000\t0.000000\tSim\n",
      "gs\t\t0.1071 ± 0.1764\t0.2680 ± 0.1781\t64673041.0000\t0.000000\tSim\n",
      "gs\t\t0.1071 ± 0.1764\t0.2680 ± 0.1781\t64673041.0000\t0.000000\tSim\n",
      "Acurácia\tOverall\t\t0.4014 ± 0.0004\t0.5751 ± 0.0011\t3186877723.0000\t0.000000\tSim\n",
      "True_prob\tOverall\t\t0.4784 ± 0.3421\t0.4670 ± 0.2262\t41720264207.5000\t0.000000\tSim\n",
      "True_prob\tgs\t\t0.1071 ± 0.1764\t0.2680 ± 0.1781\t64673041.0000\t0.000000\tSim\n"
     ]
    }
   ],
   "source": [
    "# Na tabela Precision:\n",
    "print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "# Na tabela Recall:\n",
    "print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "# Na tabela F1-Score:\n",
    "print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "# Na tabela Acurácia e True_prob:\n",
    "print(f\"Acurácia\\tOverall\\t\\t{format_value(sa_acc_mean)} ± {format_value(sa_acc_std)}\\t{format_value(ma_acc_mean)} ± {format_value(ma_acc_std)}\\t{format_value(stat_acc)}\\t{format_p_value(p_value_acc)}\\t{sig_acc}\")\n",
    "\n",
    "print(f\"True_prob\\tOverall\\t\\t{format_value(sa_true_prob_mean)} ± {format_value(sa_true_prob_std)}\\t{format_value(ma_true_prob_mean)} ± {format_value(ma_true_prob_std)}\\t{format_value(stat_true_prob)}\\t{format_p_value(p_value_true_prob)}\\t{sig_true_prob}\")\n",
    "\n",
    "# E para true_prob por classe:\n",
    "print(f\"True_prob\\t{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17612e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dados do SA (EffNet)...\n",
      "Construindo tabela ensemble do MA...\n",
      "Calculando métricas com bootstrapping...\n",
      "Preparando dados para teste de Wilcoxon...\n",
      "Executando testes de Wilcoxon...\n",
      "\n",
      "================================================================================\n",
      "TABELA DE RESULTADOS - PRECISION\n",
      "================================================================================\n",
      "Classe\t\tEFFNet (SA)\t\tENSEMBLE (MA)\t\tEstatística W\tValor-p\tSignificância\n",
      "cin\t\t0.5388 ± 0.0006\t0.6248 ± 0.0014\t709917264.0000\t0.000000\tSim\n",
      "ebv\t\t0.1030 ± 0.0007\t0.6242 ± 0.0037\t14258959.5000\t0.000000\tSim\n",
      "msi\t\t0.3844 ± 0.0008\t0.6450 ± 0.0038\t278709444.0000\t0.000000\tSim\n",
      "gs\t\t0.1650 ± 0.0008\t0.3362 ± 0.0027\t7806509.5000\t0.000000\tSim\n",
      "weighted\t\t0.3840 ± 0.0005\t0.5853 ± 0.0013\tN/A\tN/A\tN/A\n",
      "\n",
      "================================================================================\n",
      "TABELA DE RESULTADOS - RECALL\n",
      "================================================================================\n",
      "Classe\t\tEFFNet (SA)\t\tENSEMBLE (MA)\t\tEstatística W\tValor-p\tSignificância\n",
      "cin\t\t0.5968 ± 0.0005\t0.8048 ± 0.0014\t709917264.0000\t0.000000\tSim\n",
      "ebv\t\t0.0957 ± 0.0007\t0.3906 ± 0.0030\t14258959.5000\t0.000000\tSim\n",
      "msi\t\t0.3739 ± 0.0007\t0.2819 ± 0.0023\t278709444.0000\t0.000000\tSim\n",
      "gs\t\t0.1305 ± 0.0006\t0.3970 ± 0.0031\t7806509.5000\t0.000000\tSim\n",
      "weighted\t\t0.4014 ± 0.0004\t0.5751 ± 0.0011\tN/A\tN/A\tN/A\n",
      "\n",
      "================================================================================\n",
      "TABELA DE RESULTADOS - F1-SCORE\n",
      "================================================================================\n",
      "Classe\t\tEFFNet (SA)\t\tENSEMBLE (MA)\t\tEstatística W\tValor-p\tSignificância\n",
      "cin\t\t0.5663 ± 0.0005\t0.7035 ± 0.0012\t709917264.0000\t0.000000\tSim\n",
      "ebv\t\t0.0992 ± 0.0007\t0.4805 ± 0.0029\t14258959.5000\t0.000000\tSim\n",
      "msi\t\t0.3791 ± 0.0006\t0.3923 ± 0.0026\t278709444.0000\t0.000000\tSim\n",
      "gs\t\t0.1458 ± 0.0007\t0.3641 ± 0.0026\t7806509.5000\t0.000000\tSim\n",
      "weighted\t\t0.3917 ± 0.0004\t0.5554 ± 0.0012\tN/A\tN/A\tN/A\n",
      "\n",
      "================================================================================\n",
      "TABELA DE RESULTADOS - ACURÁCIA E TRUE_PROB\n",
      "================================================================================\n",
      "Métrica\t\tClasse\t\tEFFNet (SA)\t\tENSEMBLE (MA)\t\tEstatística W\tValor-p\tSignificância\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_sa'] = (df_cls['predicted_label_sa'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_ma'] = (df_cls['predicted_label_ma'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_sa'] = (df_cls['predicted_label_sa'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_ma'] = (df_cls['predicted_label_ma'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_sa'] = (df_cls['predicted_label_sa'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_ma'] = (df_cls['predicted_label_ma'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_sa'] = (df_cls['predicted_label_sa'] == cls).astype(int)\n",
      "C:\\Users\\Fernando Alves\\AppData\\Local\\Temp\\ipykernel_17416\\2920389596.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cls['accuracy_ma'] = (df_cls['predicted_label_ma'] == cls).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia\tOverall\t\t0.4014 ± 0.0004\t0.5751 ± 0.0011\t3186877723.0000\t0.000000\tSim\n",
      "True_prob\tOverall\t\t0.4784 ± 0.3421\t0.4670 ± 0.2262\t41720264207.5000\t0.000000\tSim\n",
      "True_prob\tcin\t\t0.6258 ± 0.3002\t0.5894 ± 0.1781\t12668416663.5000\t0.000000\tSim\n",
      "True_prob\tebv\t\t0.1228 ± 0.1905\t0.2930 ± 0.1951\t104147723.5000\t0.000000\tSim\n",
      "True_prob\tmsi\t\t0.3573 ± 0.2933\t0.2996 ± 0.1495\t2473763013.0000\t0.000000\tSim\n",
      "True_prob\tgs\t\t0.1071 ± 0.1764\t0.2680 ± 0.1781\t64673041.0000\t0.000000\tSim\n",
      "\n",
      "Tabela ensemble salva em: C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models\\ensemble_per_tile_soft_voting.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Configurações\n",
    "SA_FOLDS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\notebooks\\summary_results_effnet'\n",
    "MA_MODELS_DIR = r'C:\\Users\\Fernando Alves\\Documents\\WANG PIPELINE\\Wang\\MA_models'\n",
    "N_BOOTSTRAPS = 100  # Número de amostras bootstrap\n",
    "\n",
    "# Funções para processar dados (mantidas como no código anterior)\n",
    "def process_sa_data(folds_dir):\n",
    "    \"\"\"Processa todos os folds do modelo SA e retorna um DataFrame consolidado\"\"\"\n",
    "    all_sa_data = []\n",
    "    \n",
    "    fold_files = [f for f in os.listdir(folds_dir) if f.endswith('_results.csv')]\n",
    "    \n",
    "    for fold_file in fold_files:\n",
    "        fold_path = os.path.join(folds_dir, fold_file)\n",
    "        df_fold = pd.read_csv(fold_path)\n",
    "        \n",
    "        df_fold[['patient_id', 'tile_name']] = df_fold['image_path'].str.extract(\n",
    "            r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "        )\n",
    "        \n",
    "        df_fold['prob_vector'] = df_fold['probability_vector'].apply(ast.literal_eval)\n",
    "        df_fold['true_prob'] = df_fold.apply(\n",
    "            lambda row: row['prob_vector'][row['true_label']], axis=1\n",
    "        )\n",
    "        \n",
    "        df_fold['fold'] = fold_file.split('_fold')[1].split('_')[0]\n",
    "        all_sa_data.append(df_fold)\n",
    "    \n",
    "    df_sa = pd.concat(all_sa_data, ignore_index=True)\n",
    "    return df_sa\n",
    "\n",
    "def build_ensemble_table(models_dir):\n",
    "    \"\"\"Constrói a tabela ensemble a partir dos arquivos das três arquiteturas\"\"\"\n",
    "    architectures = {\n",
    "        'gg': {'file': 'merged_table_gg.csv', 'prefix': 'g'},\n",
    "        'mob': {'file': 'merged_table_mob.csv', 'prefix': 'm'}, \n",
    "        'sh': {'file': 'merged_table_sh.csv', 'prefix': 's'}\n",
    "    }\n",
    "    \n",
    "    all_models_data = []\n",
    "    \n",
    "    for arch_name, arch_info in architectures.items():\n",
    "        file_path = os.path.join(models_dir, arch_info['file'])\n",
    "        prefix = arch_info['prefix']\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df_arch = pd.read_csv(file_path)\n",
    "            \n",
    "            df_arch[['patient_id', 'tile_name']] = df_arch['image_path'].str.extract(\n",
    "                r'(TCGA-[^-]+-[^-]+).*\\/([^\\/]+\\.jpeg)'\n",
    "            )\n",
    "            \n",
    "            for i in range(10):\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    df_arch[prob_col] = df_arch[prob_col].apply(ast.literal_eval)\n",
    "            \n",
    "            all_models_data.append(df_arch)\n",
    "    \n",
    "    if not all_models_data:\n",
    "        raise ValueError(\"Nenhum dado de arquitetura foi encontrado\")\n",
    "    \n",
    "    df_ensemble = all_models_data[0][['patient_id', 'tile_name', 'true_label']].copy()\n",
    "    \n",
    "    all_probs = []\n",
    "    for df_arch in all_models_data:\n",
    "        for i in range(10):\n",
    "            for prefix in ['g', 'm', 's']:\n",
    "                prob_col = f'probability_vector_{prefix}{i}'\n",
    "                if prob_col in df_arch.columns:\n",
    "                    probs_series = df_arch[prob_col].apply(\n",
    "                        lambda x: x if isinstance(x, dict) else {}\n",
    "                    )\n",
    "                    all_probs.append(probs_series)\n",
    "    \n",
    "    mean_probs_list = []\n",
    "    true_probs_list = []\n",
    "    predicted_labels_list = []\n",
    "    predicted_probs_list = []\n",
    "    \n",
    "    for idx in range(len(df_ensemble)):\n",
    "        tile_probs = []\n",
    "        for probs_series in all_probs:\n",
    "            if idx < len(probs_series) and probs_series.iloc[idx]:\n",
    "                tile_probs.append(probs_series.iloc[idx])\n",
    "        \n",
    "        if tile_probs:\n",
    "            mean_probs = {\n",
    "                'cin': np.mean([p.get('cin', 0) for p in tile_probs]),\n",
    "                'ebv': np.mean([p.get('ebv', 0) for p in tile_probs]),\n",
    "                'msi': np.mean([p.get('msi', 0) for p in tile_probs]),\n",
    "                'gs': np.mean([p.get('gs', 0) for p in tile_probs])\n",
    "            }\n",
    "            \n",
    "            predicted_label = max(mean_probs, key=mean_probs.get)\n",
    "            predicted_prob = mean_probs[predicted_label]\n",
    "            \n",
    "            true_label = df_ensemble.iloc[idx]['true_label']\n",
    "            true_prob = mean_probs.get(true_label, 0)\n",
    "            \n",
    "            mean_probs_list.append(mean_probs)\n",
    "            true_probs_list.append(true_prob)\n",
    "            predicted_labels_list.append(predicted_label)\n",
    "            predicted_probs_list.append(predicted_prob)\n",
    "        else:\n",
    "            mean_probs_list.append({})\n",
    "            true_probs_list.append(0)\n",
    "            predicted_labels_list.append('')\n",
    "            predicted_probs_list.append(0)\n",
    "    \n",
    "    df_ensemble['mean_probs_per_class_tile'] = mean_probs_list\n",
    "    df_ensemble['true_prob'] = true_probs_list\n",
    "    df_ensemble['predicted_label'] = predicted_labels_list\n",
    "    df_ensemble['predicted_probability'] = predicted_probs_list\n",
    "    \n",
    "    return df_ensemble\n",
    "\n",
    "# Função para calcular métricas por classe usando bootstrapping\n",
    "def calculate_metrics_with_bootstrapping(df, n_bootstraps=100):\n",
    "    \"\"\"Calcula métricas usando bootstrapping para estimar variabilidade\"\"\"\n",
    "    bootstrap_metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision_cin': [], 'precision_ebv': [], 'precision_msi': [], 'precision_gs': [], 'precision_weighted': [],\n",
    "        'recall_cin': [], 'recall_ebv': [], 'recall_msi': [], 'recall_gs': [], 'recall_weighted': [],\n",
    "        'f1_cin': [], 'f1_ebv': [], 'f1_msi': [], 'f1_gs': [], 'f1_weighted': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        bootstrap_sample = resample(df, replace=True, random_state=_)\n",
    "        \n",
    "        accuracy = accuracy_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'])\n",
    "        precision = precision_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                                  average=None, labels=['cin', 'ebv', 'msi', 'gs'], zero_division=0)\n",
    "        recall = recall_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                             average=None, labels=['cin', 'ebv', 'msi', 'gs'], zero_division=0)\n",
    "        f1 = f1_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                     average=None, labels=['cin', 'ebv', 'msi', 'gs'], zero_division=0)\n",
    "        \n",
    "        precision_weighted = precision_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                                           average='weighted', zero_division=0)\n",
    "        recall_weighted = recall_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                                     average='weighted', zero_division=0)\n",
    "        f1_weighted = f1_score(bootstrap_sample['true_label'], bootstrap_sample['predicted_label'], \n",
    "                             average='weighted', zero_division=0)\n",
    "        \n",
    "        bootstrap_metrics['accuracy'].append(accuracy)\n",
    "        \n",
    "        bootstrap_metrics['precision_cin'].append(precision[0])\n",
    "        bootstrap_metrics['precision_ebv'].append(precision[1])\n",
    "        bootstrap_metrics['precision_msi'].append(precision[2])\n",
    "        bootstrap_metrics['precision_gs'].append(precision[3])\n",
    "        bootstrap_metrics['precision_weighted'].append(precision_weighted)\n",
    "        \n",
    "        bootstrap_metrics['recall_cin'].append(recall[0])\n",
    "        bootstrap_metrics['recall_ebv'].append(recall[1])\n",
    "        bootstrap_metrics['recall_msi'].append(recall[2])\n",
    "        bootstrap_metrics['recall_gs'].append(recall[3])\n",
    "        bootstrap_metrics['recall_weighted'].append(recall_weighted)\n",
    "        \n",
    "        bootstrap_metrics['f1_cin'].append(f1[0])\n",
    "        bootstrap_metrics['f1_ebv'].append(f1[1])\n",
    "        bootstrap_metrics['f1_msi'].append(f1[2])\n",
    "        bootstrap_metrics['f1_gs'].append(f1[3])\n",
    "        bootstrap_metrics['f1_weighted'].append(f1_weighted)\n",
    "    \n",
    "    result = {}\n",
    "    for metric, values in bootstrap_metrics.items():\n",
    "        if values:\n",
    "            result[f'{metric}_mean'] = np.mean(values)\n",
    "            result[f'{metric}_std'] = np.std(values, ddof=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Função para preparar dados para teste de Wilcoxon\n",
    "def prepare_wilcoxon_data(df_sa, df_ma):\n",
    "    \"\"\"Prepara dados para teste de Wilcoxon por classe\"\"\"\n",
    "    # Adicionar identificador único para cada tile\n",
    "    df_sa['tile_id'] = df_sa['patient_id'] + '_' + df_sa['tile_name']\n",
    "    df_ma['tile_id'] = df_ma['patient_id'] + '_' + df_ma['tile_name']\n",
    "    \n",
    "    # Unir os dataframes por tile_id\n",
    "    df_common = pd.merge(\n",
    "        df_sa[['tile_id', 'true_label', 'predicted_label', 'true_prob']].rename(columns={\n",
    "            'true_prob': 'true_prob_sa', \n",
    "            'predicted_label': 'predicted_label_sa'\n",
    "        }),\n",
    "        df_ma[['tile_id', 'true_label', 'predicted_label', 'true_prob']].rename(columns={\n",
    "            'true_prob': 'true_prob_ma', \n",
    "            'predicted_label': 'predicted_label_ma'\n",
    "        }),\n",
    "        on=['tile_id', 'true_label'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    return df_common\n",
    "\n",
    "# Função para executar teste de Wilcoxon por classe\n",
    "def run_wilcoxon_tests(df_common):\n",
    "    \"\"\"Executa testes de Wilcoxon para cada classe e métrica\"\"\"\n",
    "    results = {}\n",
    "    classes = ['cin', 'ebv', 'msi', 'gs']\n",
    "    \n",
    "    for cls in classes:\n",
    "        # Filtrar apenas tiles da classe atual\n",
    "        df_cls = df_common[df_common['true_label'] == cls]\n",
    "        \n",
    "        if len(df_cls) > 0:\n",
    "            # Calcular acurácia por tile (1 se correto, 0 se incorreto)\n",
    "            df_cls['accuracy_sa'] = (df_cls['predicted_label_sa'] == cls).astype(int)\n",
    "            df_cls['accuracy_ma'] = (df_cls['predicted_label_ma'] == cls).astype(int)\n",
    "            \n",
    "            # Executar teste de Wilcoxon para acurácia\n",
    "            stat_accuracy, p_value_accuracy = wilcoxon(\n",
    "                df_cls['accuracy_sa'], \n",
    "                df_cls['accuracy_ma']\n",
    "            )\n",
    "            \n",
    "            # Executar teste de Wilcoxon para true_prob\n",
    "            stat_true_prob, p_value_true_prob = wilcoxon(\n",
    "                df_cls['true_prob_sa'], \n",
    "                df_cls['true_prob_ma']\n",
    "            )\n",
    "            \n",
    "            results[cls] = {\n",
    "                'accuracy': {'stat': stat_accuracy, 'p_value': p_value_accuracy},\n",
    "                'true_prob': {'stat': stat_true_prob, 'p_value': p_value_true_prob}\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Processar dados\n",
    "print(\"Processando dados do SA (EffNet)...\")\n",
    "df_sa = process_sa_data(SA_FOLDS_DIR)\n",
    "\n",
    "print(\"Construindo tabela ensemble do MA...\")\n",
    "df_ma = build_ensemble_table(MA_MODELS_DIR)\n",
    "\n",
    "# Calcular métricas com bootstrapping\n",
    "print(\"Calculando métricas com bootstrapping...\")\n",
    "sa_bootstrap_metrics = calculate_metrics_with_bootstrapping(df_sa, N_BOOTSTRAPS)\n",
    "ma_bootstrap_metrics = calculate_metrics_with_bootstrapping(df_ma, N_BOOTSTRAPS)\n",
    "\n",
    "# Preparar dados para teste de Wilcoxon\n",
    "print(\"Preparando dados para teste de Wilcoxon...\")\n",
    "df_common = prepare_wilcoxon_data(df_sa, df_ma)\n",
    "\n",
    "# Executar testes de Wilcoxon\n",
    "print(\"Executando testes de Wilcoxon...\")\n",
    "wilcoxon_results = run_wilcoxon_tests(df_common)\n",
    "\n",
    "# Função auxiliar para formatar valores\n",
    "def format_value(value, format_str=\"{:.4f}\"):\n",
    "    if isinstance(value, (int, float, np.number)):\n",
    "        return format_str.format(value)\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Função específica para formatar valor-p com mais casas decimais\n",
    "def format_p_value(value):\n",
    "    if isinstance(value, (int, float, np.number)):\n",
    "        return \"{:.6f}\".format(value)\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Gerar tabelas de resultados\n",
    "classes = ['cin', 'ebv', 'msi', 'gs', 'weighted']\n",
    "metrics = ['precision', 'recall', 'f1']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABELA DE RESULTADOS - PRECISION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Classe\\t\\tEFFNet (SA)\\t\\tENSEMBLE (MA)\\t\\tEstatística W\\tValor-p\\tSignificância\")\n",
    "for cls in classes:\n",
    "    sa_mean = sa_bootstrap_metrics.get(f'precision_{cls}_mean', np.nan)\n",
    "    sa_std = sa_bootstrap_metrics.get(f'precision_{cls}_std', np.nan)\n",
    "    ma_mean = ma_bootstrap_metrics.get(f'precision_{cls}_mean', np.nan)\n",
    "    ma_std = ma_bootstrap_metrics.get(f'precision_{cls}_std', np.nan)\n",
    "    \n",
    "    if cls in wilcoxon_results and cls != 'weighted':\n",
    "        stat = wilcoxon_results[cls]['accuracy']['stat']\n",
    "        p_value = wilcoxon_results[cls]['accuracy']['p_value']\n",
    "        sig = \"Sim\" if p_value < 0.05 else \"Não\"\n",
    "    else:\n",
    "        stat, p_value, sig = \"N/A\", \"N/A\", \"N/A\"\n",
    "    \n",
    "    if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "        print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABELA DE RESULTADOS - RECALL\")\n",
    "print(\"=\"*80)\n",
    "print(\"Classe\\t\\tEFFNet (SA)\\t\\tENSEMBLE (MA)\\t\\tEstatística W\\tValor-p\\tSignificância\")\n",
    "for cls in classes:\n",
    "    sa_mean = sa_bootstrap_metrics.get(f'recall_{cls}_mean', np.nan)\n",
    "    sa_std = sa_bootstrap_metrics.get(f'recall_{cls}_std', np.nan)\n",
    "    ma_mean = ma_bootstrap_metrics.get(f'recall_{cls}_mean', np.nan)\n",
    "    ma_std = ma_bootstrap_metrics.get(f'recall_{cls}_std', np.nan)\n",
    "    \n",
    "    if cls in wilcoxon_results and cls != 'weighted':\n",
    "        stat = wilcoxon_results[cls]['accuracy']['stat']\n",
    "        p_value = wilcoxon_results[cls]['accuracy']['p_value']\n",
    "        sig = \"Sim\" if p_value < 0.05 else \"Não\"\n",
    "    else:\n",
    "        stat, p_value, sig = \"N/A\", \"N/A\", \"N/A\"\n",
    "    \n",
    "    if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "        print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABELA DE RESULTADOS - F1-SCORE\")\n",
    "print(\"=\"*80)\n",
    "print(\"Classe\\t\\tEFFNet (SA)\\t\\tENSEMBLE (MA)\\t\\tEstatística W\\tValor-p\\tSignificância\")\n",
    "for cls in classes:\n",
    "    sa_mean = sa_bootstrap_metrics.get(f'f1_{cls}_mean', np.nan)\n",
    "    sa_std = sa_bootstrap_metrics.get(f'f1_{cls}_std', np.nan)\n",
    "    ma_mean = ma_bootstrap_metrics.get(f'f1_{cls}_mean', np.nan)\n",
    "    ma_std = ma_bootstrap_metrics.get(f'f1_{cls}_std', np.nan)\n",
    "    \n",
    "    if cls in wilcoxon_results and cls != 'weighted':\n",
    "        stat = wilcoxon_results[cls]['accuracy']['stat']\n",
    "        p_value = wilcoxon_results[cls]['accuracy']['p_value']\n",
    "        sig = \"Sim\" if p_value < 0.05 else \"Não\"\n",
    "    else:\n",
    "        stat, p_value, sig = \"N/A\", \"N/A\", \"N/A\"\n",
    "    \n",
    "    if not np.isnan(sa_mean) and not np.isnan(ma_mean):\n",
    "        print(f\"{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABELA DE RESULTADOS - ACURÁCIA E TRUE_PROB\")\n",
    "print(\"=\"*80)\n",
    "print(\"Métrica\\t\\tClasse\\t\\tEFFNet (SA)\\t\\tENSEMBLE (MA)\\t\\tEstatística W\\tValor-p\\tSignificância\")\n",
    "\n",
    "# Acurácia geral\n",
    "sa_acc_mean = sa_bootstrap_metrics.get('accuracy_mean', np.nan)\n",
    "sa_acc_std = sa_bootstrap_metrics.get('accuracy_std', np.nan)\n",
    "ma_acc_mean = ma_bootstrap_metrics.get('accuracy_mean', np.nan)\n",
    "ma_acc_std = ma_bootstrap_metrics.get('accuracy_std', np.nan)\n",
    "\n",
    "# Calcular estatísticas de Wilcoxon para acurácia geral\n",
    "df_common['accuracy_sa'] = (df_common['predicted_label_sa'] == df_common['true_label']).astype(int)\n",
    "df_common['accuracy_ma'] = (df_common['predicted_label_ma'] == df_common['true_label']).astype(int)\n",
    "\n",
    "stat_acc, p_value_acc = wilcoxon(df_common['accuracy_sa'], df_common['accuracy_ma'])\n",
    "sig_acc = \"Sim\" if p_value_acc < 0.05 else \"Não\"\n",
    "\n",
    "print(f\"Acurácia\\tOverall\\t\\t{format_value(sa_acc_mean)} ± {format_value(sa_acc_std)}\\t{format_value(ma_acc_mean)} ± {format_value(ma_acc_std)}\\t{format_value(stat_acc)}\\t{format_p_value(p_value_acc)}\\t{sig_acc}\")\n",
    "\n",
    "# True_prob geral\n",
    "stat_true_prob, p_value_true_prob = wilcoxon(df_common['true_prob_sa'], df_common['true_prob_ma'])\n",
    "sig_true_prob = \"Sim\" if p_value_true_prob < 0.05 else \"Não\"\n",
    "\n",
    "sa_true_prob_mean = np.mean(df_common['true_prob_sa'])\n",
    "sa_true_prob_std = np.std(df_common['true_prob_sa'], ddof=1)\n",
    "ma_true_prob_mean = np.mean(df_common['true_prob_ma'])\n",
    "ma_true_prob_std = np.std(df_common['true_prob_ma'], ddof=1)\n",
    "\n",
    "print(f\"True_prob\\tOverall\\t\\t{format_value(sa_true_prob_mean)} ± {format_value(sa_true_prob_std)}\\t{format_value(ma_true_prob_mean)} ± {format_value(ma_true_prob_std)}\\t{format_value(stat_true_prob)}\\t{format_p_value(p_value_true_prob)}\\t{sig_true_prob}\")\n",
    "\n",
    "# True_prob por classe\n",
    "for cls in ['cin', 'ebv', 'msi', 'gs']:\n",
    "    df_cls = df_common[df_common['true_label'] == cls]\n",
    "    if len(df_cls) > 0:\n",
    "        stat, p_value = wilcoxon(df_cls['true_prob_sa'], df_cls['true_prob_ma'])\n",
    "        sig = \"Sim\" if p_value < 0.05 else \"Não\"\n",
    "        \n",
    "        sa_mean = np.mean(df_cls['true_prob_sa'])\n",
    "        sa_std = np.std(df_cls['true_prob_sa'], ddof=1)\n",
    "        ma_mean = np.mean(df_cls['true_prob_ma'])\n",
    "        ma_std = np.std(df_cls['true_prob_ma'], ddof=1)\n",
    "        \n",
    "        print(f\"True_prob\\t{cls}\\t\\t{format_value(sa_mean)} ± {format_value(sa_std)}\\t{format_value(ma_mean)} ± {format_value(ma_std)}\\t{format_value(stat)}\\t{format_p_value(p_value)}\\t{sig}\")\n",
    "\n",
    "# Salvar a tabela ensemble para uso futuro\n",
    "ensemble_output_path = os.path.join(MA_MODELS_DIR, 'ensemble_per_tile_soft_voting.csv')\n",
    "df_ma.to_csv(ensemble_output_path, index=False)\n",
    "print(f\"\\nTabela ensemble salva em: {ensemble_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
